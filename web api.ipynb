{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagababumo/LangChain.js/blob/main/web%20api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fab81f5-a0ca-4574-b656-5fd1719dde71",
      "metadata": {
        "id": "0fab81f5-a0ca-4574-b656-5fd1719dde71"
      },
      "source": [
        "# Lesson 6: Shipping as a web API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f6254b-5eaf-4867-999b-97d08f96cee9",
      "metadata": {
        "height": 30,
        "id": "18f6254b-5eaf-4867-999b-97d08f96cee9",
        "outputId": "a79f49b9-f5be-4017-94ec-2211f41c240f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Module: null prototype] { default: {} }"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import \"dotenv/config\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c326a7cc-d9be-432c-be10-7846d2b8e5e9",
      "metadata": {
        "height": 285,
        "id": "c326a7cc-d9be-432c-be10-7846d2b8e5e9"
      },
      "outputs": [],
      "source": [
        "import {\n",
        "  loadAndSplitChunks,\n",
        "  initializeVectorstoreWithDocuments\n",
        "} from \"./lib/helpers.ts\";\n",
        "\n",
        "const splitDocs = await loadAndSplitChunks({\n",
        "  chunkSize: 1536,\n",
        "  chunkOverlap: 128,\n",
        "});\n",
        "\n",
        "const vectorstore = await initializeVectorstoreWithDocuments({\n",
        "  documents: splitDocs,\n",
        "});\n",
        "\n",
        "const retriever = vectorstore.asRetriever();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b25e21c-28d0-4329-852e-b96a14c38529",
      "metadata": {
        "height": 149,
        "id": "8b25e21c-28d0-4329-852e-b96a14c38529"
      },
      "outputs": [],
      "source": [
        "import {\n",
        "  createDocumentRetrievalChain,\n",
        "  createRephraseQuestionChain\n",
        "} from \"./lib/helpers.ts\";\n",
        "\n",
        "const documentRetrievalChain = createDocumentRetrievalChain();\n",
        "const rephraseQuestionChain = createRephraseQuestionChain();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520b4a9b-89de-4652-b238-b7dddbd5a2c2",
      "metadata": {
        "height": 404,
        "id": "520b4a9b-89de-4652-b238-b7dddbd5a2c2"
      },
      "outputs": [],
      "source": [
        "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
        "\n",
        "const ANSWER_CHAIN_SYSTEM_TEMPLATE = `You are an experienced researcher,\n",
        "expert at interpreting and answering questions based on provided sources.\n",
        "Using the below provided context and chat history,\n",
        "answer the user's question to the best of your ability\n",
        "using only the resources provided. Be verbose!\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>`;\n",
        "\n",
        "const answerGenerationChainPrompt = ChatPromptTemplate.fromMessages([\n",
        "  [\"system\", ANSWER_CHAIN_SYSTEM_TEMPLATE],\n",
        "  new MessagesPlaceholder(\"history\"),\n",
        "  [\n",
        "    \"human\",\n",
        "    `Now, answer this question using the previous context and chat history:\n",
        "\n",
        "    {standalone_question}`\n",
        "  ]\n",
        "]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c325c8b5-9292-41f2-ad10-3ad0ad3df182",
      "metadata": {
        "height": 302,
        "id": "c325c8b5-9292-41f2-ad10-3ad0ad3df182"
      },
      "outputs": [],
      "source": [
        "import {\n",
        "  RunnablePassthrough,\n",
        "  RunnableSequence\n",
        "} from \"@langchain/core/runnables\";\n",
        "import { ChatOpenAI } from \"@langchain/openai\";\n",
        "\n",
        "const conversationalRetrievalChain = RunnableSequence.from([\n",
        "  RunnablePassthrough.assign({\n",
        "    standalone_question: rephraseQuestionChain,\n",
        "  }),\n",
        "  RunnablePassthrough.assign({\n",
        "    context: documentRetrievalChain,\n",
        "  }),\n",
        "  answerGenerationChainPrompt,\n",
        "  new ChatOpenAI({ modelName: \"gpt-3.5-turbo-1106\" }),\n",
        "]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5fe1d4c-9075-47d4-8451-b9bbc1115668",
      "metadata": {
        "height": 132,
        "id": "f5fe1d4c-9075-47d4-8451-b9bbc1115668"
      },
      "outputs": [],
      "source": [
        "import { HttpResponseOutputParser } from \"langchain/output_parsers\";\n",
        "\n",
        "// \"text/event-stream\" is also supported\n",
        "const httpResponseOutputParser = new HttpResponseOutputParser({\n",
        "  contentType: \"text/plain\"\n",
        "});"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb3853d-826c-4e1f-a413-9f9f0faf62fe",
      "metadata": {
        "height": 217,
        "id": "9cb3853d-826c-4e1f-a413-9f9f0faf62fe"
      },
      "outputs": [],
      "source": [
        "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
        "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
        "\n",
        "const messageHistory = new ChatMessageHistory();\n",
        "\n",
        "const finalRetrievalChain = new RunnableWithMessageHistory({\n",
        "  runnable: conversationalRetrievalChain,\n",
        "  getMessageHistory: (_sessionId) => messageHistory,\n",
        "  historyMessagesKey: \"history\",\n",
        "  inputMessagesKey: \"question\",\n",
        "}).pipe(httpResponseOutputParser);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecaeb6ee-d3a0-4adb-b08c-e78a7ef92321",
      "metadata": {
        "id": "ecaeb6ee-d3a0-4adb-b08c-e78a7ef92321"
      },
      "source": [
        "Additionally, we'll want to bear in mind that users should not share chat histories, and we should create a new history object per session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f81c9f-88d7-470a-b597-c4137c9d35a4",
      "metadata": {
        "height": 200,
        "id": "c8f81c9f-88d7-470a-b597-c4137c9d35a4"
      },
      "outputs": [],
      "source": [
        "const messageHistories = {};\n",
        "\n",
        "const getMessageHistoryForSession = (sessionId) => {\n",
        "    if (messageHistories[sessionId] !== undefined) {\n",
        "        return messageHistories[sessionId];\n",
        "    }\n",
        "    const newChatSessionHistory = new ChatMessageHistory();\n",
        "    messageHistories[sessionId] = newChatSessionHistory;\n",
        "    return newChatSessionHistory;\n",
        "};"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7291e9-6448-4931-bd56-f905f6324b4e",
      "metadata": {
        "id": "ae7291e9-6448-4931-bd56-f905f6324b4e"
      },
      "source": [
        "We'll recreate our final chain with this new method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bc88b0-851c-4304-a085-ac0cba9f615f",
      "metadata": {
        "height": 132,
        "id": "24bc88b0-851c-4304-a085-ac0cba9f615f"
      },
      "outputs": [],
      "source": [
        "const finalRetrievalChain = new RunnableWithMessageHistory({\n",
        "  runnable: conversationalRetrievalChain,\n",
        "  getMessageHistory: getMessageHistoryForSession,\n",
        "  inputMessagesKey: \"question\",\n",
        "  historyMessagesKey: \"history\",\n",
        "}).pipe(httpResponseOutputParser);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35a5209-e820-496b-9abc-60ade9f22d7c",
      "metadata": {
        "height": 30,
        "id": "f35a5209-e820-496b-9abc-60ade9f22d7c"
      },
      "outputs": [],
      "source": [
        "const port = 8087;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc26867-8376-4358-9525-221227967091",
      "metadata": {
        "height": 234,
        "id": "ebc26867-8376-4358-9525-221227967091"
      },
      "outputs": [],
      "source": [
        "const handler = async (request: Request): Response => {\n",
        "  const body = await request.json();\n",
        "  const stream = await finalRetrievalChain.stream({\n",
        "    question: body.question\n",
        "  }, { configurable: { sessionId: body.session_id } });\n",
        "\n",
        "  return new Response(stream, {\n",
        "    status: 200,\n",
        "    headers: {\n",
        "      \"Content-Type\": \"text/plain\"\n",
        "    },\n",
        "  });\n",
        "};"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ac36205-de1c-4cfb-81e8-9c9d1525b338",
      "metadata": {
        "height": 30,
        "id": "0ac36205-de1c-4cfb-81e8-9c9d1525b338",
        "outputId": "b54f30e3-2acb-495a-a13a-d1c4ae515db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening on http://localhost:8087/\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{\n",
              "  finished: Promise { \u001b[36m<pending>\u001b[39m },\n",
              "  shutdown: \u001b[36m[AsyncFunction: shutdown]\u001b[39m,\n",
              "  ref: \u001b[36m[Function: ref]\u001b[39m,\n",
              "  unref: \u001b[36m[Function: unref]\u001b[39m,\n",
              "  [\u001b[32mSymbol(Symbol.asyncDispose)\u001b[39m]: \u001b[36m[Function: [Symbol.asyncDispose]]\u001b[39m\n",
              "}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Deno.serve({ port }, handler);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b547772d-4f1f-48e8-b381-138b30d993af",
      "metadata": {
        "height": 336,
        "id": "b547772d-4f1f-48e8-b381-138b30d993af"
      },
      "outputs": [],
      "source": [
        "const decoder = new TextDecoder();\n",
        "\n",
        "// readChunks() reads from the provided reader and yields the results into an async iterable\n",
        "function readChunks(reader) {\n",
        "  return {\n",
        "    async* [Symbol.asyncIterator]() {\n",
        "      let readResult = await reader.read();\n",
        "      while (!readResult.done) {\n",
        "        yield decoder.decode(readResult.value);\n",
        "        readResult = await reader.read();\n",
        "      }\n",
        "    },\n",
        "  };\n",
        "}\n",
        "\n",
        "const sleep = async () => {\n",
        "  return new Promise((resolve) => setTimeout(resolve, 500));\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac25b85d-dd40-42a1-8374-6c778e86c9d8",
      "metadata": {
        "height": 353,
        "id": "ac25b85d-dd40-42a1-8374-6c778e86c9d8",
        "outputId": "84eea2a0-0824-452a-9d04-d5acb1f23f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHUNK: Based o\n",
            "CHUNK: n the provided c\n",
            "CHUNK: ontext an\n",
            "CHUNK: d chat his\n",
            "CHUNK: tory, the requ\n",
            "CHUNK: irements fo\n",
            "CHUNK: r the course t\n",
            "CHUNK: aught by\n",
            "CHUNK:  instructor Andr\n",
            "CHUNK: ew Ng includ\n",
            "CHUNK: e familiarity \n",
            "CHUNK: with basi\n",
            "CHUNK: c probability \n",
            "CHUNK: and statistics. Thi\n",
            "CHUNK: s includes knowledge\n",
            "CHUNK:  of rand\n",
            "CHUNK: om varia\n",
            "CHUNK: bles, expectati\n",
            "CHUNK: on, variance,\n",
            "CHUNK:  and other fo\n",
            "CHUNK: undationa\n",
            "CHUNK: l concepts. The\n",
            "CHUNK:  instructor mentions that mos\n",
            "CHUNK: t undergr\n",
            "CHUNK: aduate\n",
            "CHUNK:  statistics class\n",
            "CHUNK: es, such as\n",
            "CHUNK:  Stat 116 at\n",
            "CHUNK:  Stanford, wil\n",
            "CHUNK: l cover the nece\n",
            "CHUNK: ssary mater\n",
            "CHUNK: ial.\n",
            "\n",
            "Further\n",
            "CHUNK: more, basic \n",
            "CHUNK: familiarity with linear algebra i\n",
            "CHUNK: s also assum\n",
            "CHUNK: ed. This includes underst\n",
            "CHUNK: anding of ma\n",
            "CHUNK: trices, v\n",
            "CHUNK: ectors, matrix \n",
            "CHUNK: multiplic\n",
            "CHUNK: ation, and matrix inver\n",
            "CHUNK: se. Courses like Math\n",
            "CHUNK:  51, 103,\n",
            "CHUNK:  Math 113, or \n",
            "CHUNK: CS205 at Stanford are\n",
            "CHUNK:  mentioned as providing s\n",
            "CHUNK: ufficien\n",
            "CHUNK: t background\n",
            "CHUNK:  for this requirement.\n",
            "CHUNK: \n",
            "\n",
            "In terms of p\n",
            "CHUNK: rogrammin\n",
            "CHUNK: g, the course doe\n",
            "CHUNK: s involve pro\n",
            "CHUNK: gramming, primarily in MA\n",
            "CHUNK: TLAB or Oc\n",
            "CHUNK: tave. Th\n",
            "CHUNK: e instructor specifie\n",
            "CHUNK: s that there is no C\n",
            "CHUNK:  programming required\n",
            "CHUNK:  for the course, a\n",
            "CHUNK: part from po\n",
            "CHUNK: tential us\n",
            "CHUNK: e in the end s\n",
            "CHUNK: emester\n",
            "CHUNK:  project. The emp\n",
            "CHUNK: hasis is\n",
            "CHUNK:  on understanding big-O \n",
            "CHUNK: notation and data\n",
            "CHUNK:  structures ra\n",
            "CHUNK: ther than a\n",
            "CHUNK:  specific programming lan\n",
            "CHUNK: guage such as \n",
            "CHUNK: C or Java.\n",
            "CHUNK: \n",
            "\n",
            "Lastly, the \n",
            "CHUNK: course does not have\n",
            "CHUNK:  a heavy\n",
            "CHUNK:  focus on \n",
            "CHUNK: programming and is not ve\n",
            "CHUNK: ry programming i\n",
            "CHUNK: ntensiv\n",
            "CHUNK: e, as mentioned by the \n",
            "CHUNK: instructor. This suggests that wh\n",
            "CHUNK: ile familiarity with programming is ben\n",
            "CHUNK: eficial, it\n",
            "CHUNK:  is not a strict\n",
            "CHUNK:  requirement for the course.\n",
            "\n",
            "In \n",
            "CHUNK: summary, the requirements for this course include familiarity with basic probability and statistics, as well as basic linear algebra. A foundational understanding of programming concepts and the ability to use MATLAB or Octave for assignments is also beneficial.\n"
          ]
        }
      ],
      "source": [
        "const response = await fetch(`http://localhost:${port}`, {\n",
        "    method: \"POST\",\n",
        "    headers: {\n",
        "        \"content-type\": \"application/json\",\n",
        "    },\n",
        "    body: JSON.stringify({\n",
        "        question: \"What are the prerequisites for this course?\",\n",
        "        session_id: \"1\", // Should randomly generate/assign\n",
        "    })\n",
        "});\n",
        "\n",
        "// response.body is a ReadableStream\n",
        "const reader = response.body?.getReader();\n",
        "\n",
        "for await (const chunk of readChunks(reader)) {\n",
        "  console.log(\"CHUNK:\", chunk);\n",
        "}\n",
        "\n",
        "await sleep();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7af107da-cf4c-4900-a456-d131ff8fbc80",
      "metadata": {
        "height": 336,
        "id": "7af107da-cf4c-4900-a456-d131ff8fbc80",
        "outputId": "ab90ce9b-5d05-4cbc-b5c9-d586c16fe1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHUNK: Certainly! Base\n",
            "CHUNK: d on the\n",
            "CHUNK:  provided\n",
            "CHUNK:  context \n",
            "CHUNK: and chat his\n",
            "CHUNK: tory, here \n",
            "CHUNK: are the prerequisit\n",
            "CHUNK: es for th\n",
            "CHUNK: is course in\n",
            "CHUNK:  bullet poin\n",
            "CHUNK: t format:\n",
            "\n",
            "- Famili\n",
            "CHUNK: arity with bas\n",
            "CHUNK: ic probabil\n",
            "CHUNK: ity and statistics\n",
            "CHUNK: , including kno\n",
            "CHUNK: wledge of ra\n",
            "CHUNK: ndom var\n",
            "CHUNK: iables, e\n",
            "CHUNK: xpectation\n",
            "CHUNK: , and variance\n",
            "CHUNK: . Most u\n",
            "CHUNK: ndergradu\n",
            "CHUNK: ate statistics class\n",
            "CHUNK: es, such as Stat\n",
            "CHUNK:  116 at Sta\n",
            "CHUNK: nford, cove\n",
            "CHUNK: r the necessary mater\n",
            "CHUNK: ial.\n",
            "- Bas\n",
            "CHUNK: ic familiarity with lin\n",
            "CHUNK: ear algebra\n",
            "CHUNK: , including understan\n",
            "CHUNK: ding of matric\n",
            "CHUNK: es, vectors,\n",
            "CHUNK:  matrix multipl\n",
            "CHUNK: ication, and matri\n",
            "CHUNK: x inverse. C\n",
            "CHUNK: ourses like Math\n",
            "CHUNK:  51, 103,\n",
            "CHUNK:  Math 113, or CS\n",
            "CHUNK: 205 at Stanford are mentioned\n",
            "CHUNK:  as providing sufficie\n",
            "CHUNK: nt backgr\n",
            "CHUNK: ound for\n",
            "CHUNK:  this requirement\n",
            "CHUNK: .\n",
            "- The ability to\n",
            "CHUNK:  understand big-O notation\n",
            "CHUNK:  and knowledge of data s\n",
            "CHUNK: tructures such as \n",
            "CHUNK: linked lis\n",
            "CHUNK: ts, queu\n",
            "CHUNK: es, and bin\n",
            "CHUNK: ary trees. While spec\n",
            "CHUNK: ific programming \n",
            "CHUNK: languag\n",
            "CHUNK: es like C or Java are \n",
            "CHUNK: not required,\n",
            "CHUNK:  understanding these fun\n",
            "CHUNK: damental conce\n",
            "CHUNK: pts is im\n",
            "CHUNK: portant\n",
            "CHUNK: .\n",
            "- Proficiency\n",
            "CHUNK:  in using MATLAB\n",
            "CHUNK:  or Octave for \n",
            "CHUNK: programming assignments. The course is not heavily programming intensive, and there is no C programming required apart from potential use in the end semester project.\n",
            "\n",
            "These are the main prerequisites outlined by the instructor based on the provided sources.\n"
          ]
        }
      ],
      "source": [
        "const response = await fetch(`http://localhost:${port}`, {\n",
        "  method: \"POST\",\n",
        "  headers: {\n",
        "    \"content-type\": \"application/json\",\n",
        "  },\n",
        "  body: JSON.stringify({\n",
        "    question: \"Can you list them in bullet point format?\",\n",
        "    session_id: \"1\", // Should randomly generate/assign\n",
        "  })\n",
        "});\n",
        "\n",
        "// response.body is a ReadableStream\n",
        "const reader = response.body?.getReader();\n",
        "\n",
        "for await (const chunk of readChunks(reader)) {\n",
        "  console.log(\"CHUNK:\", chunk);\n",
        "}\n",
        "\n",
        "await sleep();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbcaa28f-5057-4109-80c1-406ec47bd9eb",
      "metadata": {
        "height": 336,
        "id": "fbcaa28f-5057-4109-80c1-406ec47bd9eb",
        "outputId": "417c12d7-018f-4381-8e12-6472543f4172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHUNK: Based on the cont\n",
            "CHUNK: ext and chat \n",
            "CHUNK: history provi\n",
            "CHUNK: ded, you \n",
            "CHUNK: didn't exp\n",
            "CHUNK: licitly ask a q\n",
            "CHUNK: uestion,\n",
            "CHUNK:  but you did re\n",
            "CHUNK: quest for the oth\n",
            "CHUNK: er person to\n",
            "CHUNK:  repeat w\n",
            "CHUNK: hat you had s\n",
            "CHUNK: aid. It \n",
            "CHUNK: seems like\n",
            "CHUNK:  there may h\n",
            "CHUNK: ave been so\n",
            "CHUNK: me background nois\n",
            "CHUNK: e or an is\n",
            "CHUNK: sue with the cl\n",
            "CHUNK: arity of\n",
            "CHUNK:  the communica\n",
            "CHUNK: tion. The conve\n",
            "CHUNK: rsation also t\n",
            "CHUNK: ouched on the topic\n",
            "CHUNK:  of audio recording and \n",
            "CHUNK: separating v\n",
            "CHUNK: oices, so \n",
            "CHUNK: it's possible that\n",
            "CHUNK:  there was a t\n",
            "CHUNK: echnical discu\n",
            "CHUNK: ssion relate\n",
            "CHUNK: d to that.\n",
            "\n",
            "In gen\n",
            "CHUNK: eral, ask\n",
            "CHUNK: ing for repetition\n",
            "CHUNK:  in a con\n",
            "CHUNK: versation can occur du\n",
            "CHUNK: e to various reasons\n",
            "CHUNK:  such as noise \n",
            "CHUNK: interfer\n",
            "CHUNK: ence, un\n",
            "CHUNK: clear sp\n",
            "CHUNK: eech, or a\n",
            "CHUNK:  simple\n",
            "CHUNK:  request for clarification. It's \n",
            "CHUNK: importan\n",
            "CHUNK: t to ensure \n",
            "CHUNK: clear communication, es\n",
            "CHUNK: pecially\n",
            "CHUNK:  in situation\n",
            "CHUNK: s where there may be background noise or multiple speakers.\n",
            "\n",
            "If there's a specific aspect of the conversation or context that you'd like to explore further or if there's a specific question you have in mind, feel free to provide more details for me to assist you better.\n"
          ]
        }
      ],
      "source": [
        "const response = await fetch(`http://localhost:${port}`, {\n",
        "  method: \"POST\",\n",
        "  headers: {\n",
        "    \"content-type\": \"application/json\",\n",
        "  },\n",
        "  body: JSON.stringify({\n",
        "    question: \"What did I just ask you?\",\n",
        "    session_id: \"2\", // Should randomly generate/assign\n",
        "  })\n",
        "});\n",
        "\n",
        "// response.body is a ReadableStream\n",
        "const reader = response.body?.getReader();\n",
        "\n",
        "for await (const chunk of readChunks(reader)) {\n",
        "  console.log(\"CHUNK:\", chunk);\n",
        "}\n",
        "\n",
        "await sleep();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464b5f7d-75e0-4366-8adf-48053f19229d",
      "metadata": {
        "height": 30,
        "id": "464b5f7d-75e0-4366-8adf-48053f19229d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e50feff9-72d1-4c1a-96b9-ec80ccde87f9",
      "metadata": {
        "height": 30,
        "id": "e50feff9-72d1-4c1a-96b9-ec80ccde87f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "258343e5-e488-4c2c-938b-8c3189ef959d",
      "metadata": {
        "height": 30,
        "id": "258343e5-e488-4c2c-938b-8c3189ef959d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec20e0c-389f-4cd1-b5df-67f6d706fb4e",
      "metadata": {
        "height": 30,
        "id": "6ec20e0c-389f-4cd1-b5df-67f6d706fb4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b2b76f-f963-4226-95f1-42d15487f0ca",
      "metadata": {
        "height": 30,
        "id": "a4b2b76f-f963-4226-95f1-42d15487f0ca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a497d1-0587-431b-bc54-657e935af6df",
      "metadata": {
        "height": 30,
        "id": "99a497d1-0587-431b-bc54-657e935af6df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12805d9a-d5fe-48d5-acf3-d88a929e9d21",
      "metadata": {
        "height": 30,
        "id": "12805d9a-d5fe-48d5-acf3-d88a929e9d21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d65826-7917-4a51-b937-37d3d460c5eb",
      "metadata": {
        "height": 30,
        "id": "56d65826-7917-4a51-b937-37d3d460c5eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc803c79-ef69-4539-b2eb-da3cd89cb134",
      "metadata": {
        "height": 30,
        "id": "fc803c79-ef69-4539-b2eb-da3cd89cb134"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca4ed79-d80a-4d26-9832-1c13b7eb9085",
      "metadata": {
        "height": 30,
        "id": "9ca4ed79-d80a-4d26-9832-1c13b7eb9085"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241f7da1-51d2-4bc8-8ea8-a76eb80a70cf",
      "metadata": {
        "height": 30,
        "id": "241f7da1-51d2-4bc8-8ea8-a76eb80a70cf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c838bf09-8369-4942-a78f-73a94b74d602",
      "metadata": {
        "height": 30,
        "id": "c838bf09-8369-4942-a78f-73a94b74d602"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nb_converter": "script",
      "pygments_lexer": "typescript",
      "version": "5.3.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}